#!/usr/bin/env python

import argparse
import sys
import os
import json
import random

import pymongo

import neatview
from neatview import Neatview
import dgeo
import dpy
import Flickr
import GeoMeanShift

# deprecate
m = pymongo.Connection()
ltte = m.ltte

nv = Neatview()

def run_mean_shift(cell):
   initial_point = cell.center()
   lat = initial_point[1]
   lng = initial_point[0]
   print str(lat) + ", " + str(lng)
   ms = GeoMeanShift.GeoMeanShift([lat, lng], 0.005)
   start_id = ltte.mean_shifts.insert( { 'index': 0,  'first': True, 'location': [lat, lng] } )
   print start_id
   i = 1
   while not ms.done() and ms.step():
      lat = ms.current_mean()[0]
      lng = ms.current_mean()[1]
      ltte.mean_shifts.insert( { 'start': start_id, 'index': i,  'location': [lat, lng] } )
      print ms.current_mean()
      i = i + 1

def do_grid(args):
   bbox = json.load(file(args.region_of_interest_metadata))['bbox']
   grid = dgeo.GeoGrid(bbox['left'], bbox['right'], bbox['top'], bbox['bottom'], args.number_across)
   grid.foreach_cell(run_mean_shift)

def load_roi(roi_path):
   bbox = dgeo.LatLngBoundingBox(json.load(file(roi_path))['bbox'])
   return bbox

# deprecate
def photos_in_roi(roi_path):
   bbox = load_roi(roi_path)
   return ltte.photos.find({
      'location': {
         '$within': {
	    '$box': [
	       [bbox.bottom, bbox.left],
	       [bbox.top, bbox.right]
	    ]
	 }
      }
   })

# deprecate
def clusters_in_bbox(roi_path):
   bbox = load_roi(roi_path)
   return ltte.clusters.find({'center': {'$within': {'$box': [[bbox.bottom, bbox.left], [bbox.top, bbox.right]]}}})

def _list_meanshifts(args):
   results = clusters_in_bbox(args.region_of_interest_metadata)
   for ms in results:
      print ms

def _clear_meanshifts(args):
   bbox = load_roi(args.region_of_interest_metadata)
   print "clearing meanshifts in ROI " + args.region_of_interest_metadata
   count = ltte.clusters.remove({'center': {'$within': {'$box': [[bbox.bottom, bbox.left], [bbox.top, bbox.right]]}}})

def _debug_clear(args):
  ltte.debug_mesh.remove()
  print "debug cleared"

def _plot_photos(args):
   #from PIL import Image, ImageDraw
   import numpy as np
   from skimage.io import imsave
   bbox = dgeo.LatLngBoundingBox(json.load(file(args.roi_path))['bbox'])
  
   print "Will color points by cluster: " + str(args.labels)
   colors = dict()
   if args.labels:
      for cluster in ltte.clusters.find():
         if bbox.contains(cluster['center']):
	    colors[cluster['_id']] = dpy.random_color3f()

   #plot = Image.new("L", (1024, int(1024 / bbox.aspect())))
   plot = np.zeros((1024, int(1024/bbox.aspect()), 3))

   print "plot photos in ROI " + args.roi_path
   count = 0
   for photo in ltte.photos.find({}, {'location':1, 'cluster':1}):
   #for photo in photos.find():

      #print photo['location']
      if bbox.contains(photo['location']):
         if count % 1000 == 0:
            print count
         # draw the point in the image
	 normal_pos = bbox.normalize(photo['location'])
	 x = plot.shape[0] * normal_pos[1]
	 y = plot.shape[1] * normal_pos[0]
	 if not args.labels:
            plot[x, y, 0] = plot[x, y, 0] + 1
            plot[x, y, 1] = plot[x, y, 1] + 1
            plot[x, y, 2] = plot[x, y, 2] + 1
	 else:
	    plot[x, y] = colors[photo['cluster']]

         count = count + 1
   if not args.labels:
      plot /= float(plot.max())
      plot = np.power(plot, 1.0 / 16.0)

   image_path = "data/plots/" + os.path.basename(args.roi_path) + str(count) + ".png"
   dpy.ensure_dir('data/plots')
   imsave(image_path, np.rot90(plot))
   print "Plotted " + str(count) + " photos to " + image_path

def _sklearn_meanshift(args):
   import numpy as np
   from sklearn.cluster import MeanShift, estimate_bandwidth
   from convexhull import convexHull

   bbox = dgeo.LatLngBoundingBox(json.load(file(args.roi_path))['bbox'])
   
   print "sklearn MeanShift of ROI " + args.roi_path
   
   # get points in bbox (move to MongoDB query!)
   point = ltte.photos.find_one()['location']
   photo_locations = None
   ids = []
   count = 0
   #for photo in photos.find({}, {'location':1}):
      #if bbox.contains(photo['location']):
   for photo in photos_in_roi(args.roi_path):
	 if photo_locations == None:
	    photo_locations = np.array(photo['location'])
	 else:
	    photo_locations = np.vstack((photo_locations, photo['location']))
	 ids.append(photo['_id'])
         count = count + 1

   # do meanshift
   ms = MeanShift(bandwidth=0.003, bin_seeding=True)
   ms.fit(photo_locations)
   labels = ms.labels_
   cluster_centers = ms.cluster_centers_
  
   # organize/count photos by cluster
   cluster_points = [ [] for center in cluster_centers ]
   cluster_sizes = [ 0 for center in cluster_centers ]
   for p in range(0, len(labels)):
     cluster_index = labels[p]
     cluster_sizes[cluster_index] = cluster_sizes[cluster_index] + 1
     
     point = photo_locations[p]
     cluster_points[cluster_index].append(tuple(point.tolist()))

   # compute convex hull of each cluster
   convex_hulls = []
   for points in cluster_points:
     points_unique = list(set(points))

     if len(points_unique) < 4:
       convex_hulls.append(points_unique)
     else:
       _convex_hull = convexHull(points_unique)
       convex_hulls.append(_convex_hull)

   # print stats
   labels_unique = np.unique(labels)
   n_clusters_ = len(labels_unique)
   print "number of clusters : %d" % n_clusters_
   print "number of photos : %d" % len(labels)
   
   # insert clusters in DB
   label = 0
   cluster_ids = []
   for center in cluster_centers:
      
      latitude = center[0]
      longitude = center[1]
      _id = ltte.clusters.insert({
        'center': [latitude, longitude],
	'label':label,
	'count':cluster_sizes[label],
	'convex_hull':convex_hulls[label]
      })
      cluster_ids.append(_id)
      label = label + 1

   # set photos' cluster foreign keys
   i = 0
   for _id in ids:
      #print "label " + str(labels[i])
      cluster_sizes[labels[i]] = cluster_sizes[labels[i]] + 1
      ltte.photos.update({'_id':_id}, {"$set": {'cluster':cluster_ids[labels[i]]}})
      i = i + 1
   #print "updated " + str(i) + " photo.cluster foreign keys"

def _representative_images(args):
   #import cv2
   import numpy as np
   from scipy.misc import fromimage
   from skimage.io import imread
   from skimage.exposure import histogram
   import skimage
   from bson import objectid
   from PIL import Image
   from Flickr import MirroredPhoto
   

   clusters = []

   if args.cluster:
     cluster_id = objectid.ObjectId(args.cluster)
     clusters.append(ltte.clusters.find_one({'_id':cluster_id}))
   else:
     print "ROI mode: ", args.roi
     clusters_cursor = clusters_in_bbox(args.roi)
     for cluster in clusters_cursor:
       clusters.append(cluster)

   print ""
   cluster_index = 0
   for cluster in clusters:
     cluster_index += 1
     cluster_id = cluster['_id']
     photos = ltte.photos.find({'cluster':cluster['_id']})
     total_photos = photos.count()
     photo_count = 0
     average_histogram = None
     images = []
     for photo in photos:
       mp = MirroredPhoto(photo)
       
       #PIL
       image = Image.open(mp.jpg_path())
       size = fromimage(image).size
       histogram = image.histogram()
       histogram = map(lambda value: float(value) / float(size), histogram)
       histogram = np.array(histogram)
       
       images.append((histogram, mp))

       if average_histogram == None:
         average_histogram = histogram
       else:
         average_histogram = (photo_count * average_histogram + histogram) / float(photo_count + 1)

       #print photo
       photo_count += 1

       print "\rcluster ", cluster_index, "of", len(clusters), ',', cluster['_id'], ':', photo_count, "of", total_photos, "histogrammed",

     print str(photo_count) + " photos in cluster " + str(cluster['_id'])
     print "Finding representative image..."
     
     min_diff = None
     min_image = None
     for (histogram, mp) in images:
       diff = np.sum(np.square(histogram - average_histogram))
       if min_diff == None:
         min_diff = diff
	 min_image = mp
       if diff < min_diff:
         diff = min_diff
	 min_image = mp

     print "image closest to average histogram: ", min_image.jpg_path()
     
     ltte.clusters.update(
       {'_id' : cluster_id},
       {'$addToSet' :
         {'representative_images' :
	   {'histogram' : min_image.dbid}
	 }
       }
     )

     #print average_histogram
     #print "sum: ", np.sum(average_histogram)

def _voronoi(args):

  roi = load_roi(args.roi)
  print "Computing Voronoi layout for", args.roi
  
  tile = nv.tile(roi)

  neatview.builder.layout(tile)


def _random_photos(args):
  import shutil
  random_photos = []
  for i in range(0, args.N):
    random_photos.append(random_photo())
  dpy.ensure_dir(args.destination_directory)
  for image in random_photos:
    shutil.copy(image.jpg_path(), args.destination_directory + "/" + image.flickr_locator_string() + ".jpg")
    #print "cp " + image.jpg_path() + " " + args.destination_directory + "/" + image.flickr_locator_string() + ".jpg"

def random_photo():
  count = ltte.photos.count()
  index = random.randint(0, count)
  random_photo = ltte.photos.find().skip(index).limit(1).next()
  return Flickr.MirroredPhoto(random_photo)

def _build_map(args):
  import shutil
  import Console
  from PIL import Image
  out = args.output_path
  print "Building map to " + out
  dpy.ensure_dir(os.path.join(out, 'static'))
  dpy.ensure_dir(os.path.join(out, 'static/js'))
  dpy.ensure_dir(os.path.join(out, 'static/css'))
  dpy.ensure_dir(os.path.join(out, 'static/flickr'))
  dpy.ensure_dir(os.path.join(out, 'static/img'))
  dpy.ensure_dir(os.path.join(out, 'static/tile'))
  shutil.copyfile('static/index.html', os.path.join(args.output_path, 'index.html'))
  shutil.copyfile('static/Console.js', os.path.join(out, 'static/Console.js'))
  shutil.copyfile('static/js/neatview.js', os.path.join(out, 'static/js/neatview.js'))
  shutil.copyfile('static/js/dgeo.js', os.path.join(out, 'static/js/dgeo.js'))
  shutil.copyfile('static/js/three.min.js', os.path.join(out, 'static/js/three.js'))
  shutil.copyfile('static/js/Detector.js', os.path.join(out, 'static/js/Detector.js'))
  shutil.copyfile('static/css/neatview.css', os.path.join(out, 'static/css/neatview.css'))
  shutil.copyfile('static/img/grid.png', os.path.join(out, 'static/img/grid.png'))
  shutil.copyfile('static/tile/all', os.path.join(out, 'static/tile/all'))
  
  tile = json.load(open('static/tile/all', 'r'))

  for cluster in tile['clusters']:
    if 'image' in cluster:
      image_dir = os.path.dirname(cluster['image']['image_url'])
      dpy.ensure_dir(os.path.join(out, image_dir))

      big_image = Image.open(cluster['image']['image_url'])
      big_image.thumbnail((512, 512))
      big_image.save(os.path.join(out, cluster['image']['image_url']))


parser = argparse.ArgumentParser()
subparsers = parser.add_subparsers(dest='command')

# geo_store_all
geo_store_all_parser = subparsers.add_parser('geo_store_all')
geo_store_all_parser.set_defaults(func=Flickr.geo_store_all)

# mean_shift_grid
mean_shift_grid = subparsers.add_parser('mean_shift_grid')
mean_shift_grid.add_argument('region_of_interest_metadata', type=str)
mean_shift_grid.add_argument('number_across', type=int)
mean_shift_grid.set_defaults(func=do_grid)

# clear_meanshifts
clear_meanshifts = subparsers.add_parser('clear_meanshifts')
clear_meanshifts.add_argument('region_of_interest_metadata', type=str)
clear_meanshifts.set_defaults(func=_clear_meanshifts)

# list_meanshifts
list_meanshifts = subparsers.add_parser('list_meanshifts')
list_meanshifts.add_argument('region_of_interest_metadata', type=str)
list_meanshifts.set_defaults(func=_list_meanshifts)

# sklearn_meanshift
sklearn_meanshift = subparsers.add_parser('sklearn_meanshift')
sklearn_meanshift.add_argument('roi_path', type=str)
sklearn_meanshift.set_defaults(func=_sklearn_meanshift)

# compute voronoi cluster layout
voronoi = subparsers.add_parser('voronoi')
voronoi.add_argument('roi', type=str)
voronoi.set_defaults(func=_voronoi)

# debug data
debug_clear = subparsers.add_parser('debug_clear')
debug_clear.set_defaults(func=_debug_clear)

# compute representative images
representative_images = subparsers.add_parser('representative_images')
clusters_of_interest = representative_images.add_mutually_exclusive_group(required=True)
clusters_of_interest.add_argument('-r', '--roi', type=str)
clusters_of_interest.add_argument('-c', '--cluster', type=str)
representative_images.set_defaults(func=_representative_images)

# plot photos
sklearn_meanshift = subparsers.add_parser('plot_photos')
sklearn_meanshift.add_argument('roi_path', type=str)
sklearn_meanshift.add_argument('--labels', dest='labels', action='store_const',
                               const=True, default=False, help='color code points by cluster')
sklearn_meanshift.set_defaults(func=_plot_photos)

# random photos
random_photos = subparsers.add_parser('random')
random_photos.add_argument('N', type=int)
random_photos.add_argument('destination_directory', type=str)
random_photos.set_defaults(func=_random_photos)

# build static-host-able map
build_map = subparsers.add_parser('build_map')
build_map.add_argument('output_path', type=str)
build_map.set_defaults(func=_build_map)

args = parser.parse_args()
args.func(args)

